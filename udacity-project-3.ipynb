{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-08-28T04:07:52.046340Z",
     "iopub.status.busy": "2023-08-28T04:07:52.045500Z",
     "iopub.status.idle": "2023-08-28T04:10:23.170061Z",
     "shell.execute_reply": "2023-08-28T04:10:23.168903Z",
     "shell.execute_reply.started": "2023-08-28T04:07:52.046303Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless==4.5.3.56\n",
      "  Downloading opencv-python-headless-4.5.3.56.tar.gz (89.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[860 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.6\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version >= \"3.6\" and sys_platform == \"linux\" and platform_machine == \"aarch64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version >= \"3.6\" and sys_platform == \"darwin\" and platform_machine == \"arm64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.7\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version == \"3.8\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Collecting setuptools\n",
      "  \u001b[31m   \u001b[0m   Downloading setuptools-68.1.2-py3-none-any.whl (805 kB)\n",
      "  \u001b[31m   \u001b[0m \u001b[?25l                                              0.0/805.1 kB ? eta -:--:--\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 805.1/805.1 kB 24.4 MB/s eta 0:00:00\n",
      "  \u001b[31m   \u001b[0m \u001b[?25hCollecting wheel\n",
      "  \u001b[31m   \u001b[0m   Downloading wheel-0.41.2-py3-none-any.whl (64 kB)\n",
      "  \u001b[31m   \u001b[0m \u001b[?25l                                              0.0/64.8 kB ? eta -:--:--\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.8/64.8 kB 7.2 MB/s eta 0:00:00\n",
      "  \u001b[31m   \u001b[0m \u001b[?25hCollecting scikit-build\n",
      "  \u001b[31m   \u001b[0m   Downloading scikit_build-0.17.6-py3-none-any.whl (84 kB)\n",
      "  \u001b[31m   \u001b[0m \u001b[?25l                                              0.0/84.3 kB ? eta -:--:--\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.3/84.3 kB 8.3 MB/s eta 0:00:00\n",
      "  \u001b[31m   \u001b[0m \u001b[?25hCollecting cmake\n",
      "  \u001b[31m   \u001b[0m   Downloading cmake-3.27.4-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n",
      "  \u001b[31m   \u001b[0m \u001b[?25l                                              0.0/26.1 MB ? eta -:--:--\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━╸                                  4.5/26.1 MB 134.1 MB/s eta 0:00:01\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━╸                            8.4/26.1 MB 143.3 MB/s eta 0:00:01\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━                       11.7/26.1 MB 111.7 MB/s eta 0:00:01\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━╸              17.1/26.1 MB 111.8 MB/s eta 0:00:01\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸      22.6/26.1 MB 152.3 MB/s eta 0:00:01\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 26.1/26.1 MB 154.4 MB/s eta 0:00:01\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 26.1/26.1 MB 154.4 MB/s eta 0:00:01\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 26.1/26.1 MB 154.4 MB/s eta 0:00:01\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 26.1/26.1 MB 154.4 MB/s eta 0:00:01\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.1/26.1 MB 50.2 MB/s eta 0:00:00\n",
      "  \u001b[31m   \u001b[0m \u001b[?25hCollecting pip\n",
      "  \u001b[31m   \u001b[0m   Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
      "  \u001b[31m   \u001b[0m \u001b[?25l                                              0.0/2.1 MB ? eta -:--:--\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 72.1 MB/s eta 0:00:00\n",
      "  \u001b[31m   \u001b[0m \u001b[?25hCollecting numpy==1.19.3\n",
      "  \u001b[31m   \u001b[0m   Downloading numpy-1.19.3.zip (7.3 MB)\n",
      "  \u001b[31m   \u001b[0m \u001b[?25l                                              0.0/7.3 MB ? eta -:--:--\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸            5.2/7.3 MB 172.3 MB/s eta 0:00:01\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 7.3/7.3 MB 122.9 MB/s eta 0:00:01\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.3/7.3 MB 75.8 MB/s eta 0:00:00\n",
      "  \u001b[31m   \u001b[0m \u001b[?25h  Installing build dependencies: started\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: started\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m Collecting distro (from scikit-build)\n",
      "  \u001b[31m   \u001b[0m   Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting packaging (from scikit-build)\n",
      "  \u001b[31m   \u001b[0m   Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
      "  \u001b[31m   \u001b[0m \u001b[?25l                                              0.0/48.9 kB ? eta -:--:--\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 4.4 MB/s eta 0:00:00\n",
      "  \u001b[31m   \u001b[0m \u001b[?25hCollecting tomli (from scikit-build)\n",
      "  \u001b[31m   \u001b[0m   Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "  \u001b[31m   \u001b[0m Building wheels for collected packages: numpy\n",
      "  \u001b[31m   \u001b[0m   Building wheel for numpy (pyproject.toml): started\n",
      "  \u001b[31m   \u001b[0m   Building wheel for numpy (pyproject.toml): still running...\n",
      "  \u001b[31m   \u001b[0m   Building wheel for numpy (pyproject.toml): finished with status 'error'\n",
      "  \u001b[31m   \u001b[0m   error: subprocess-exited-with-error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   × Building wheel for numpy (pyproject.toml) did not run successfully.\n",
      "  \u001b[31m   \u001b[0m   │ exit code: 1\n",
      "  \u001b[31m   \u001b[0m   ╰─> [791 lines of output]\n",
      "  \u001b[31m   \u001b[0m       setup.py:67: RuntimeWarning: NumPy 1.19.3 may not yet support Python 3.10.\n",
      "  \u001b[31m   \u001b[0m         warnings.warn(\n",
      "  \u001b[31m   \u001b[0m       Running from numpy source directory.\n",
      "  \u001b[31m   \u001b[0m       /tmp/pip-install-anizx46j/numpy_1b6591403ea648539a591dd33e0f9f6c/tools/cythonize.py:67: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  \u001b[31m   \u001b[0m         from distutils.version import LooseVersion\n",
      "  \u001b[31m   \u001b[0m       numpy/random/_bounded_integers.pxd.in has not changed\n",
      "  \u001b[31m   \u001b[0m       numpy/random/_pcg64.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m       Processing numpy/random/_bounded_integers.pyx\n",
      "  \u001b[31m   \u001b[0m       numpy/random/_generator.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m       numpy/random/_philox.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m       numpy/random/_bounded_integers.pyx.in has not changed\n",
      "  \u001b[31m   \u001b[0m       numpy/random/bit_generator.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m       numpy/random/_sfc64.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m       numpy/random/_mt19937.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m       numpy/random/mtrand.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m       numpy/random/_common.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m       Cythonizing sources\n",
      "  \u001b[31m   \u001b[0m       blas_opt_info:\n",
      "  \u001b[31m   \u001b[0m       blas_mkl_info:\n",
      "  \u001b[31m   \u001b[0m       customize UnixCCompiler\n",
      "  \u001b[31m   \u001b[0m         FOUND:\n",
      "  \u001b[31m   \u001b[0m           libraries = ['mkl_rt', 'pthread']\n",
      "  \u001b[31m   \u001b[0m           library_dirs = ['/opt/conda/lib']\n",
      "  \u001b[31m   \u001b[0m           define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "  \u001b[31m   \u001b[0m           include_dirs = ['/usr/local/include', '/usr/include', '/opt/conda/include']\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         FOUND:\n",
      "  \u001b[31m   \u001b[0m           libraries = ['mkl_rt', 'pthread']\n",
      "  \u001b[31m   \u001b[0m           library_dirs = ['/opt/conda/lib']\n",
      "  \u001b[31m   \u001b[0m           define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "  \u001b[31m   \u001b[0m           include_dirs = ['/usr/local/include', '/usr/include', '/opt/conda/include']\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m       non-existing path in 'numpy/distutils': 'site.cfg'\n",
      "  \u001b[31m   \u001b[0m       lapack_opt_info:\n",
      "  \u001b[31m   \u001b[0m       lapack_mkl_info:\n",
      "  \u001b[31m   \u001b[0m         FOUND:\n",
      "  \u001b[31m   \u001b[0m           libraries = ['mkl_rt', 'pthread']\n",
      "  \u001b[31m   \u001b[0m           library_dirs = ['/opt/conda/lib']\n",
      "  \u001b[31m   \u001b[0m           define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "  \u001b[31m   \u001b[0m           include_dirs = ['/usr/local/include', '/usr/include', '/opt/conda/include']\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         FOUND:\n",
      "  \u001b[31m   \u001b[0m           libraries = ['mkl_rt', 'pthread']\n",
      "  \u001b[31m   \u001b[0m           library_dirs = ['/opt/conda/lib']\n",
      "  \u001b[31m   \u001b[0m           define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]\n",
      "  \u001b[31m   \u001b[0m           include_dirs = ['/usr/local/include', '/usr/include', '/opt/conda/include']\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m       /opt/conda/lib/python3.10/distutils/dist.py:274: UserWarning: Unknown distribution option: 'define_macros'\n",
      "  \u001b[31m   \u001b[0m         warnings.warn(msg)\n",
      "  \u001b[31m   \u001b[0m       running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m       running build\n",
      "  \u001b[31m   \u001b[0m       running config_cc\n",
      "  \u001b[31m   \u001b[0m       unifing config_cc, config, build_clib, build_ext, build commands --compiler options\n",
      "  \u001b[31m   \u001b[0m       running config_fc\n",
      "  \u001b[31m   \u001b[0m       unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options\n",
      "  \u001b[31m   \u001b[0m       running build_src\n",
      "  \u001b[31m   \u001b[0m       build_src\n",
      "  \u001b[31m   \u001b[0m       building py_modules sources\n",
      "  \u001b[31m   \u001b[0m       building library \"npymath\" sources\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable gfortran\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable f95\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable ifort\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable ifc\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable lf95\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable pgfortran\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable nvfortran\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable f90\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable f77\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable fort\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable efort\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable efc\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable g77\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable g95\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable pathf95\n",
      "  \u001b[31m   \u001b[0m       Could not locate executable nagfor\n",
      "  \u001b[31m   \u001b[0m       don't know how to compile Fortran code on platform 'posix'\n",
      "  \u001b[31m   \u001b[0m         adding 'build/src.linux-x86_64-3.10/numpy/core/src/npymath' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m       None - nothing done with h_files = ['build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_internal.h']\n",
      "  \u001b[31m   \u001b[0m       building library \"npysort\" sources\n",
      "  \u001b[31m   \u001b[0m         adding 'build/src.linux-x86_64-3.10/numpy/core/src/common' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m       None - nothing done with h_files = ['build/src.linux-x86_64-3.10/numpy/core/src/common/npy_sort.h', 'build/src.linux-x86_64-3.10/numpy/core/src/common/npy_partition.h', 'build/src.linux-x86_64-3.10/numpy/core/src/common/npy_binsearch.h']\n",
      "  \u001b[31m   \u001b[0m       building library \"npyrandom\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.core._multiarray_tests\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.core._multiarray_umath\" sources\n",
      "  \u001b[31m   \u001b[0m         adding 'build/src.linux-x86_64-3.10/numpy/core/src/umath' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m         adding 'build/src.linux-x86_64-3.10/numpy/core/src/npymath' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m         adding 'build/src.linux-x86_64-3.10/numpy/core/src/common' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m       numpy.core - nothing done with h_files = ['build/src.linux-x86_64-3.10/numpy/core/src/umath/funcs.inc', 'build/src.linux-x86_64-3.10/numpy/core/src/umath/simd.inc', 'build/src.linux-x86_64-3.10/numpy/core/src/umath/loops.h', 'build/src.linux-x86_64-3.10/numpy/core/src/umath/matmul.h', 'build/src.linux-x86_64-3.10/numpy/core/src/umath/clip.h', 'build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_internal.h', 'build/src.linux-x86_64-3.10/numpy/core/src/common/templ_common.h', 'build/src.linux-x86_64-3.10/numpy/core/include/numpy/config.h', 'build/src.linux-x86_64-3.10/numpy/core/include/numpy/_numpyconfig.h', 'build/src.linux-x86_64-3.10/numpy/core/include/numpy/__multiarray_api.h', 'build/src.linux-x86_64-3.10/numpy/core/include/numpy/__ufunc_api.h']\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.core._umath_tests\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.core._rational_tests\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.core._struct_ufunc_tests\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.core._operand_flag_tests\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.fft._pocketfft_internal\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.linalg.lapack_lite\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.linalg._umath_linalg\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.random._mt19937\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.random._philox\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.random._pcg64\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.random._sfc64\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.random._common\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.random.bit_generator\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.random._generator\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.random._bounded_integers\" sources\n",
      "  \u001b[31m   \u001b[0m       building extension \"numpy.random.mtrand\" sources\n",
      "  \u001b[31m   \u001b[0m       building data_files sources\n",
      "  \u001b[31m   \u001b[0m       build_src: building npy-pkg config files\n",
      "  \u001b[31m   \u001b[0m       running build_py\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       copying numpy/_globals.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ctypeslib.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       copying numpy/__init__.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       copying numpy/version.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       copying numpy/conftest.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       copying numpy/dual.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       copying numpy/_pytesttester.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       copying numpy/matlib.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       copying numpy/_distributor_init.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       copying numpy/setup.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       copying build/src.linux-x86_64-3.10/numpy/__config__.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/compat\n",
      "  \u001b[31m   \u001b[0m       copying numpy/compat/__init__.py -> build/lib.linux-x86_64-3.10/numpy/compat\n",
      "  \u001b[31m   \u001b[0m       copying numpy/compat/py3k.py -> build/lib.linux-x86_64-3.10/numpy/compat\n",
      "  \u001b[31m   \u001b[0m       copying numpy/compat/_inspect.py -> build/lib.linux-x86_64-3.10/numpy/compat\n",
      "  \u001b[31m   \u001b[0m       copying numpy/compat/setup.py -> build/lib.linux-x86_64-3.10/numpy/compat\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/compat/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/compat/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/compat/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/compat/tests/test_compat.py -> build/lib.linux-x86_64-3.10/numpy/compat/tests\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/_exceptions.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/einsumfunc.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/getlimits.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/__init__.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/shape_base.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/_dtype.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/_add_newdocs.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/defchararray.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/fromnumeric.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/_asarray.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/numerictypes.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/arrayprint.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/_string_helpers.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/_dtype_ctypes.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/records.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/machar.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/_methods.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/_ufunc_config.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/overrides.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/umath_tests.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/memmap.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/function_base.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/setup_common.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/numeric.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/_internal.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/cversions.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/setup.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/multiarray.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/umath.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/_type_aliases.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/code_generators/generate_numpy_api.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test__exceptions.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_extint128.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_indexing.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_indexerrors.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_unicode.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_scalarbuffer.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_protocols.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_scalar_ctors.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_conversion_utils.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_numerictypes.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_shape_base.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_scalarprint.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_multiarray.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_longdouble.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_defchararray.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_overrides.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_item_selection.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_einsum.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_mem_overlap.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_scalar_methods.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_ufunc.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_print.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_function_base.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_half.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_datetime.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_numeric.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_cpu_features.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_scalarinherit.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_getlimits.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_deprecations.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_errstate.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/_locales.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_umath_complex.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_umath.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_arrayprint.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_dtype.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_abc.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_scalarmath.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_memmap.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_umath_accuracy.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_api.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_machar.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_records.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/core/tests/test_nditer.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/misc_util.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/from_template.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/mingw32ccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/__init__.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/msvccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/system_info.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/numpy_distribution.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/exec_command.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/cpuinfo.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/npy_pkg_config.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/extension.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/log.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/ccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/_shell_utils.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/conv_template.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/line_endings.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/pathccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/intelccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/unixccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/msvc9compiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/lib2def.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/setup.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/core.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       copying build/src.linux-x86_64-3.10/numpy/distutils/__config__.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/build.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/install_headers.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/build_src.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/__init__.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/bdist_rpm.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/config_compiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/install_data.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/build_scripts.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/autodist.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/build_ext.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/sdist.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/install.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/config.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/build_clib.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/egg_info.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/install_clib.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/build_py.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/command/develop.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/intel.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/__init__.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/compaq.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/hpux.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/environment.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/nag.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/sun.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/ibm.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/mips.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/pathf95.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/g95.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/lahey.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/none.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/nv.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/vast.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/gnu.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/pg.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/fcompiler/absoft.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/tests/test_exec_command.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/tests/test_fcompiler_nagfor.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/tests/test_fcompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/tests/test_mingw32ccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/tests/test_system_info.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/tests/test_from_template.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/tests/test_misc_util.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/tests/test_fcompiler_gnu.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/tests/test_npy_pkg_config.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/tests/test_fcompiler_intel.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/distutils/tests/test_shell_utils.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/__init__.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/subclassing.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/internals.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/dispatch.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/byteswapping.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/basics.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/structured_arrays.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/broadcasting.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/misc.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/creation.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/glossary.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/constants.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/ufuncs.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       copying numpy/doc/indexing.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/common_rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/__init__.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/capi_maps.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/f2py2e.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/use_rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/crackfortran.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/cb_rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/cfuncs.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/f90mod_rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/diagnose.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/f2py_testing.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/__main__.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/__version__.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/setup.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/auxfuncs.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/func2subr.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_compile_function.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_kind.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_crackfortran.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_block_docstring.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_parameter.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_return_logical.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_array_from_pyobj.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_mixed.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_common.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_size.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_assumed_shape.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_return_real.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_return_character.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_return_integer.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_quoted_character.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_semicolon_split.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/util.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_return_complex.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_string.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/f2py/tests/test_callback.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/fft\n",
      "  \u001b[31m   \u001b[0m       copying numpy/fft/helper.py -> build/lib.linux-x86_64-3.10/numpy/fft\n",
      "  \u001b[31m   \u001b[0m       copying numpy/fft/__init__.py -> build/lib.linux-x86_64-3.10/numpy/fft\n",
      "  \u001b[31m   \u001b[0m       copying numpy/fft/_pocketfft.py -> build/lib.linux-x86_64-3.10/numpy/fft\n",
      "  \u001b[31m   \u001b[0m       copying numpy/fft/setup.py -> build/lib.linux-x86_64-3.10/numpy/fft\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/fft/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/fft/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/fft/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/fft/tests/test_helper.py -> build/lib.linux-x86_64-3.10/numpy/fft/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/fft/tests/test_pocketfft.py -> build/lib.linux-x86_64-3.10/numpy/fft/tests\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/ufunclike.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/type_check.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/npyio.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/_iotools.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/__init__.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/scimath.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/shape_base.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/financial.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/polynomial.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/arraypad.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/index_tricks.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/arrayterator.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/utils.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/mixins.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/function_base.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/stride_tricks.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/histograms.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/_version.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/format.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/user_array.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/_datasource.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/arraysetops.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/recfunctions.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/nanfunctions.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/twodim_base.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/setup.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_format.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_arraysetops.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_utils.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test__version.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_shape_base.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_twodim_base.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_type_check.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_histograms.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_mixins.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_packbits.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_ufunclike.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_arrayterator.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_function_base.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_arraypad.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_polynomial.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test__datasource.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_index_tricks.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_stride_tricks.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_recfunctions.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_financial.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_nanfunctions.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test_io.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/lib/tests/test__iotools.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/linalg\n",
      "  \u001b[31m   \u001b[0m       copying numpy/linalg/__init__.py -> build/lib.linux-x86_64-3.10/numpy/linalg\n",
      "  \u001b[31m   \u001b[0m       copying numpy/linalg/linalg.py -> build/lib.linux-x86_64-3.10/numpy/linalg\n",
      "  \u001b[31m   \u001b[0m       copying numpy/linalg/setup.py -> build/lib.linux-x86_64-3.10/numpy/linalg\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/linalg/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/linalg/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/linalg/tests/test_linalg.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/linalg/tests/test_deprecations.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/linalg/tests/test_build.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/bench.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/__init__.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/mrecords.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/testutils.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/timer_comparison.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/extras.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/setup.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/core.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/tests/test_deprecations.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/tests/test_extras.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/tests/test_core.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/tests/test_old_ma.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/tests/test_subclassing.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/ma/tests/test_mrecords.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/matrixlib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/matrixlib/__init__.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/matrixlib/defmatrix.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib\n",
      "  \u001b[31m   \u001b[0m       copying numpy/matrixlib/setup.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/matrixlib/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/matrixlib/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/matrixlib/tests/test_multiarray.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/matrixlib/tests/test_defmatrix.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/matrixlib/tests/test_numeric.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/matrixlib/tests/test_interaction.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/matrixlib/tests/test_matrix_linalg.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/matrixlib/tests/test_masked_matrix.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/_polybase.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/__init__.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/hermite_e.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/legendre.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/polynomial.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/polyutils.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/laguerre.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/chebyshev.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/hermite.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/setup.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/tests/test_laguerre.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/tests/test_chebyshev.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/tests/test_legendre.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/tests/test_printing.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/tests/test_hermite_e.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/tests/test_polyutils.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/tests/test_polynomial.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/tests/test_hermite.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/polynomial/tests/test_classes.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/random\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/__init__.py -> build/lib.linux-x86_64-3.10/numpy/random\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/_pickle.py -> build/lib.linux-x86_64-3.10/numpy/random\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/setup.py -> build/lib.linux-x86_64-3.10/numpy/random\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/tests/test_randomstate_regression.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/tests/test_smoke.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/tests/test_random.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/tests/test_generator_mt19937.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/tests/test_randomstate.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/tests/test_generator_mt19937_regressions.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/tests/test_direct.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/tests/test_extending.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/random/tests/test_seed_sequence.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/testing\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/print_coercion_tables.py -> build/lib.linux-x86_64-3.10/numpy/testing\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/__init__.py -> build/lib.linux-x86_64-3.10/numpy/testing\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/utils.py -> build/lib.linux-x86_64-3.10/numpy/testing\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/setup.py -> build/lib.linux-x86_64-3.10/numpy/testing\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/_private/__init__.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/_private/parameterized.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/_private/noseclasses.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/_private/utils.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/_private/nosetester.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/_private/decorators.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/tests/test_utils.py -> build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/tests/test_decorators.py -> build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/testing/tests/test_doctesting.py -> build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m       creating build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/tests/test_ctypeslib.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/tests/test_warnings.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/tests/test_matlib.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/tests/test_numpy_version.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/tests/test_scripts.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/tests/test_reloading.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m       copying numpy/tests/test_public_api.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m       running build_clib\n",
      "  \u001b[31m   \u001b[0m       customize UnixCCompiler\n",
      "  \u001b[31m   \u001b[0m       customize UnixCCompiler using new_build_clib\n",
      "  \u001b[31m   \u001b[0m       building 'npymath' library\n",
      "  \u001b[31m   \u001b[0m       compiling C sources\n",
      "  \u001b[31m   \u001b[0m       C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/numpy/core/src\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/numpy/core/src/npymath\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/build\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/npymath\n",
      "  \u001b[31m   \u001b[0m       compile options: '-Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/npymath/npy_math.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/ieee754.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_complex.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/npymath/halffloat.c\n",
      "  \u001b[31m   \u001b[0m       ar: adding 4 object files to build/temp.linux-x86_64-3.10/libnpymath.a\n",
      "  \u001b[31m   \u001b[0m       building 'npysort' library\n",
      "  \u001b[31m   \u001b[0m       compiling C sources\n",
      "  \u001b[31m   \u001b[0m       C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/npysort\n",
      "  \u001b[31m   \u001b[0m       compile options: '-Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/quicksort.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/mergesort.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/timsort.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/heapsort.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/radixsort.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/selection.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/binsearch.c\n",
      "  \u001b[31m   \u001b[0m       ar: adding 7 object files to build/temp.linux-x86_64-3.10/libnpysort.a\n",
      "  \u001b[31m   \u001b[0m       building 'npyrandom' library\n",
      "  \u001b[31m   \u001b[0m       compiling C sources\n",
      "  \u001b[31m   \u001b[0m       C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/numpy/random\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/numpy/random/src\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/numpy/random/src/distributions\n",
      "  \u001b[31m   \u001b[0m       compile options: '-Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/random/src/distributions/logfactorial.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/random/src/distributions/distributions.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/random/src/distributions/random_mvhg_count.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/random/src/distributions/random_mvhg_marginals.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/random/src/distributions/random_hypergeometric.c\n",
      "  \u001b[31m   \u001b[0m       ar: adding 5 object files to build/temp.linux-x86_64-3.10/libnpyrandom.a\n",
      "  \u001b[31m   \u001b[0m       running build_ext\n",
      "  \u001b[31m   \u001b[0m       customize UnixCCompiler\n",
      "  \u001b[31m   \u001b[0m       customize UnixCCompiler using new_build_ext\n",
      "  \u001b[31m   \u001b[0m       building 'numpy.core._multiarray_tests' extension\n",
      "  \u001b[31m   \u001b[0m       compiling C sources\n",
      "  \u001b[31m   \u001b[0m       C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/numpy/core/src/common\n",
      "  \u001b[31m   \u001b[0m       compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/common/mem_overlap.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/_multiarray_tests.c\n",
      "  \u001b[31m   \u001b[0m       gcc -pthread -B /opt/conda/compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/opt/conda/lib -Wl,-rpath-link,/opt/conda/lib -L/opt/conda/lib build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray/_multiarray_tests.o build/temp.linux-x86_64-3.10/numpy/core/src/common/mem_overlap.o -Lbuild/temp.linux-x86_64-3.10 -lnpymath -o build/lib.linux-x86_64-3.10/numpy/core/_multiarray_tests.cpython-310-x86_64-linux-gnu.so\n",
      "  \u001b[31m   \u001b[0m       building 'numpy.core._multiarray_umath' extension\n",
      "  \u001b[31m   \u001b[0m       compiling C sources\n",
      "  \u001b[31m   \u001b[0m       C compiler: gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/numpy/core/src/multiarray\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/numpy/core/src/umath\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/umath\n",
      "  \u001b[31m   \u001b[0m       creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/common\n",
      "  \u001b[31m   \u001b[0m       compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DSCIPY_MKL_H -DHAVE_CBLAS -I/usr/local/include -I/usr/include -I/opt/conda/include -Ibuild/src.linux-x86_64-3.10/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/alloc.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/common.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/arrayobject.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/convert.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/convert_datatype.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/arraytypes.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/conversion_utils.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/ctors.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/datetime.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/datetime_strings.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/datetime_busday.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/datetime_busdaycal.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/descriptor.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/dragon4.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/array_assign_scalar.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/dtype_transfer.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/array_assign_array.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/arrayfunction_override.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/buffer.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/calculation.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/einsum.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/compiled_base.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/lowlevel_strided_loops.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/flagsobject.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/getset.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/hashdescr.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/item_selection.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/iterators.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/refcount.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/sequence.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/shape.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/scalarapi.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.c\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src: In function ‘float_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2967:27: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2967:12: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));\n",
      "  \u001b[31m   \u001b[0m             |            ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src: In function ‘cfloat_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2975:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2975 |     hashreal = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m             |                               ^~~~~~~~\n",
      "  \u001b[31m   \u001b[0m             |                               |\n",
      "  \u001b[31m   \u001b[0m             |                               double\n",
      "  \u001b[31m   \u001b[0m        2976 |             PyArrayScalar_VAL(obj, C@name@).real);\n",
      "  \u001b[31m   \u001b[0m             |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2975:16: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2975 |     hashreal = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m             |                ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2981:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2981 |     hashimag = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m             |                               ^~~~~~~~\n",
      "  \u001b[31m   \u001b[0m             |                               |\n",
      "  \u001b[31m   \u001b[0m             |                               double\n",
      "  \u001b[31m   \u001b[0m        2982 |             PyArrayScalar_VAL(obj, C@name@).imag);\n",
      "  \u001b[31m   \u001b[0m             |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2981:16: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2981 |     hashimag = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m             |                ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src: In function ‘longdouble_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2967:27: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2967:12: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));\n",
      "  \u001b[31m   \u001b[0m             |            ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src: In function ‘clongdouble_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2975:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2975 |     hashreal = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m             |                               ^~~~~~~~\n",
      "  \u001b[31m   \u001b[0m             |                               |\n",
      "  \u001b[31m   \u001b[0m             |                               double\n",
      "  \u001b[31m   \u001b[0m        2976 |             PyArrayScalar_VAL(obj, C@name@).real);\n",
      "  \u001b[31m   \u001b[0m             |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2975:16: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2975 |     hashreal = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m             |                ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2981:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2981 |     hashimag = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m             |                               ^~~~~~~~\n",
      "  \u001b[31m   \u001b[0m             |                               |\n",
      "  \u001b[31m   \u001b[0m             |                               double\n",
      "  \u001b[31m   \u001b[0m        2982 |             PyArrayScalar_VAL(obj, C@name@).imag);\n",
      "  \u001b[31m   \u001b[0m             |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2981:16: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2981 |     hashimag = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m             |                ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src: In function ‘half_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2997:27: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2997 |     return _Py_HashDouble(npy_half_to_double(PyArrayScalar_VAL(obj, Half)));\n",
      "  \u001b[31m   \u001b[0m             |                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m             |                           |\n",
      "  \u001b[31m   \u001b[0m             |                           double\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2997:12: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m        2997 |     return _Py_HashDouble(npy_half_to_double(PyArrayScalar_VAL(obj, Half)));\n",
      "  \u001b[31m   \u001b[0m             |            ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       In file included from /opt/conda/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m                        from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m       /opt/conda/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m          10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m             |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src: In function ‘longdouble_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2968:1: warning: control reaches end of non-void function [-Wreturn-type]\n",
      "  \u001b[31m   \u001b[0m        2968 | }\n",
      "  \u001b[31m   \u001b[0m             | ^\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src: In function ‘float_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2968:1: warning: control reaches end of non-void function [-Wreturn-type]\n",
      "  \u001b[31m   \u001b[0m        2968 | }\n",
      "  \u001b[31m   \u001b[0m             | ^\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src: In function ‘half_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m       numpy/core/src/multiarray/scalartypes.c.src:2998:1: warning: control reaches end of non-void function [-Wreturn-type]\n",
      "  \u001b[31m   \u001b[0m        2998 | }\n",
      "  \u001b[31m   \u001b[0m             | ^\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/vdot.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/umath/umathmodule.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/umath/reduction.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/loops.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/mapping.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/methods.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/multiarraymodule.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/nditer_templ.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/nditer_api.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/nditer_constr.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/nditer_pywrap.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/multiarray/number.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/umath/ufunc_type_resolution.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/umath/override.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/npymath/npy_math.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/ieee754.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_complex.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/npymath/halffloat.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/common/array_assign.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/common/mem_overlap.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/common/npy_longdouble.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/common/ucsnarrow.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/common/ufunc_override.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/common/numpyos.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/common/npy_cpu_features.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/common/cblasfuncs.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/common/python_xerbla.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/matmul.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/clip.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/umath/ufunc_object.c\n",
      "  \u001b[31m   \u001b[0m       gcc: numpy/core/src/umath/extobj.c\n",
      "  \u001b[31m   \u001b[0m       gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/scalarmath.c\n",
      "  \u001b[31m   \u001b[0m       error: Command \"gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DSCIPY_MKL_H -DHAVE_CBLAS -I/usr/local/include -I/usr/include -I/opt/conda/include -Ibuild/src.linux-x86_64-3.10/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/opt/conda/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.c -o build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.o -MMD -MF build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.o.d\" failed with exit status 1\n",
      "  \u001b[31m   \u001b[0m       [end of output]\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m   ERROR: Failed building wheel for numpy\n",
      "  \u001b[31m   \u001b[0m Failed to build numpy\n",
      "  \u001b[31m   \u001b[0m ERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless==4.5.3.56 matplotlib==3.4.3 numpy==1.21.2 pillow==7.0.0 bokeh==2.1.1 torch==1.11.0 torchvision==0.12.0 tqdm==4.63.0 ipywidgets==7.6.5 livelossplot==0.5.4 pytest==7.1.1 pandas==1.3.5 seaborn==0.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-08-28T04:10:23.173461Z",
     "iopub.status.busy": "2023-08-28T04:10:23.172777Z",
     "iopub.status.idle": "2023-08-28T04:10:35.144913Z",
     "shell.execute_reply": "2023-08-28T04:10:35.143682Z",
     "shell.execute_reply.started": "2023-08-28T04:10:23.173423Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting livelossplot\n",
      "  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from livelossplot) (3.7.1)\n",
      "Requirement already satisfied: bokeh in /opt/conda/lib/python3.10/site-packages (from livelossplot) (3.1.1)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (1.23.5)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (21.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (1.5.3)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (9.5.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (6.0)\n",
      "Requirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (6.3.2)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (2023.5.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->bokeh->livelossplot) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n",
      "Installing collected packages: livelossplot\n",
      "Successfully installed livelossplot-0.5.5\n"
     ]
    }
   ],
   "source": [
    "!pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T04:10:35.148005Z",
     "iopub.status.busy": "2023-08-28T04:10:35.147623Z",
     "iopub.status.idle": "2023-08-28T04:10:35.375130Z",
     "shell.execute_reply": "2023-08-28T04:10:35.373640Z",
     "shell.execute_reply.started": "2023-08-28T04:10:35.147966Z"
    }
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Let's see if we have an available GPU\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    if use_cuda:\n",
    "        print(\"GPU available\")\n",
    "    else:\n",
    "        print(\"GPU *NOT* available. Will use CPU (slow)\")\n",
    "\n",
    "    # Seed random generator for repeatibility\n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Download data if not present already\n",
    "    download_and_extract()\n",
    "    compute_mean_and_std()\n",
    "\n",
    "    # Make checkpoints subdir if not existing\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    \n",
    "    # Make sure we can reach the installed binaries. This is needed for the workspace\n",
    "    if os.path.exists(\"/data/DLND/C2/landmark_images\"):\n",
    "        os.environ['PATH'] = f\"{os.environ['PATH']}:/root/.local/bin\"\n",
    "\n",
    "\n",
    "def get_data_location():\n",
    "    \"\"\"\n",
    "    Find the location of the dataset, either locally or in the Udacity workspace\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.exists(\"landmark_images\"):\n",
    "        data_folder = \"landmark_images\"\n",
    "    elif os.path.exists(\"/data/DLND/C2/landmark_images\"):\n",
    "        data_folder = \"/data/DLND/C2/landmark_images\"\n",
    "    else:\n",
    "        raise IOError(\"Please download the dataset first\")\n",
    "\n",
    "    return data_folder\n",
    "\n",
    "\n",
    "def download_and_extract(\n",
    "    url=\"https://udacity-dlnfd.s3-us-west-1.amazonaws.com/datasets/landmark_images.zip\",\n",
    "):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        location = get_data_location()\n",
    "    \n",
    "    except IOError:\n",
    "        # Dataset does not exist\n",
    "        print(f\"Downloading and unzipping {url}. This will take a while...\")\n",
    "\n",
    "        with urllib.request.urlopen(url) as resp:\n",
    "\n",
    "            with ZipFile(BytesIO(resp.read())) as fp:\n",
    "\n",
    "                fp.extractall(\".\")\n",
    "\n",
    "        print(\"done\")\n",
    "                \n",
    "    else:\n",
    "        \n",
    "        print(\n",
    "            \"Dataset already downloaded. If you need to re-download, \"\n",
    "            f\"please delete the directory {location}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "# Compute image normalization\n",
    "def compute_mean_and_std():\n",
    "    \"\"\"\n",
    "    Compute per-channel mean and std of the dataset (to be used in transforms.Normalize())\n",
    "    \"\"\"\n",
    "\n",
    "    cache_file = \"mean_and_std.pt\"\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"Reusing cached mean and std\")\n",
    "        d = torch.load(cache_file)\n",
    "\n",
    "        return d[\"mean\"], d[\"std\"]\n",
    "\n",
    "    folder = get_data_location()\n",
    "    ds = datasets.ImageFolder(\n",
    "        folder, transform=transforms.Compose([transforms.ToTensor()])\n",
    "    )\n",
    "    dl = torch.utils.data.DataLoader(\n",
    "        ds, batch_size=1, num_workers=0\n",
    "    )\n",
    "\n",
    "    mean = 0.0\n",
    "    for images, _ in tqdm(dl, total=len(ds), desc=\"Computing mean\", ncols=80):\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "    mean = mean / len(dl.dataset)\n",
    "\n",
    "    var = 0.0\n",
    "    npix = 0\n",
    "    for images, _ in tqdm(dl, total=len(ds), desc=\"Computing std\", ncols=80):\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        var += ((images - mean.unsqueeze(1)) ** 2).sum([0, 2])\n",
    "        npix += images.nelement()\n",
    "\n",
    "    std = torch.sqrt(var / (npix / 3))\n",
    "\n",
    "    # Cache results so we don't need to redo the computation\n",
    "    torch.save({\"mean\": mean, \"std\": std}, cache_file)\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def after_subplot(ax: plt.Axes, group_name: str, x_label: str):\n",
    "    \"\"\"Add title xlabel and legend to single chart\"\"\"\n",
    "    ax.set_title(group_name)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.legend(loc=\"center right\")\n",
    "\n",
    "    if group_name.lower() == \"loss\":\n",
    "        ax.set_ylim([None, 4.5])\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(pred, truth):\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    gt = pd.Series(truth, name='Ground Truth')\n",
    "    predicted = pd.Series(pred, name='Predicted')\n",
    "\n",
    "    confusion_matrix = pd.crosstab(gt, predicted)\n",
    "\n",
    "    fig, sub = plt.subplots(figsize=(14, 12))\n",
    "    with sns.plotting_context(\"notebook\"):\n",
    "        idx = (confusion_matrix == 0)\n",
    "        confusion_matrix[idx] = np.nan\n",
    "        sns.heatmap(confusion_matrix, annot=True, ax=sub, linewidths=0.5, linecolor='lightgray', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T04:10:35.380179Z",
     "iopub.status.busy": "2023-08-28T04:10:35.379211Z",
     "iopub.status.idle": "2023-08-28T04:10:35.437117Z",
     "shell.execute_reply": "2023-08-28T04:10:35.436124Z",
     "shell.execute_reply.started": "2023-08-28T04:10:35.380143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n",
      "Dataset already downloaded. If you need to re-download, please delete the directory landmark_images\n",
      "Reusing cached mean and std\n"
     ]
    }
   ],
   "source": [
    "setup_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T04:10:35.438893Z",
     "iopub.status.busy": "2023-08-28T04:10:35.438568Z",
     "iopub.status.idle": "2023-08-28T04:10:35.462163Z",
     "shell.execute_reply": "2023-08-28T04:10:35.461133Z",
     "shell.execute_reply.started": "2023-08-28T04:10:35.438861Z"
    }
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Let's see if we have an available GPU\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    if use_cuda:\n",
    "        print(\"GPU available\")\n",
    "    else:\n",
    "        print(\"GPU *NOT* available. Will use CPU (slow)\")\n",
    "\n",
    "    # Seed random generator for repeatibility\n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Download data if not present already\n",
    "    download_and_extract()\n",
    "    compute_mean_and_std()\n",
    "\n",
    "    # Make checkpoints subdir if not existing\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    \n",
    "    # Make sure we can reach the installed binaries. This is needed for the workspace\n",
    "    if os.path.exists(\"/data/DLND/C2/landmark_images\"):\n",
    "        os.environ['PATH'] = f\"{os.environ['PATH']}:/root/.local/bin\"\n",
    "\n",
    "\n",
    "def get_data_location():\n",
    "    \"\"\"\n",
    "    Find the location of the dataset, either locally or in the Udacity workspace\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.exists(\"landmark_images\"):\n",
    "        data_folder = \"landmark_images\"\n",
    "    elif os.path.exists(\"/data/DLND/C2/landmark_images\"):\n",
    "        data_folder = \"/data/DLND/C2/landmark_images\"\n",
    "    else:\n",
    "        raise IOError(\"Please download the dataset first\")\n",
    "\n",
    "    return data_folder\n",
    "\n",
    "\n",
    "def download_and_extract(\n",
    "    url=\"https://udacity-dlnfd.s3-us-west-1.amazonaws.com/datasets/landmark_images.zip\",\n",
    "):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        location = get_data_location()\n",
    "    \n",
    "    except IOError:\n",
    "        # Dataset does not exist\n",
    "        print(f\"Downloading and unzipping {url}. This will take a while...\")\n",
    "\n",
    "        with urllib.request.urlopen(url) as resp:\n",
    "\n",
    "            with ZipFile(BytesIO(resp.read())) as fp:\n",
    "\n",
    "                fp.extractall(\".\")\n",
    "\n",
    "        print(\"done\")\n",
    "                \n",
    "    else:\n",
    "        \n",
    "        print(\n",
    "            \"Dataset already downloaded. If you need to re-download, \"\n",
    "            f\"please delete the directory {location}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "# Compute image normalization\n",
    "def compute_mean_and_std():\n",
    "    \"\"\"\n",
    "    Compute per-channel mean and std of the dataset (to be used in transforms.Normalize())\n",
    "    \"\"\"\n",
    "\n",
    "    cache_file = \"mean_and_std.pt\"\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"Reusing cached mean and std\")\n",
    "        d = torch.load(cache_file)\n",
    "\n",
    "        return d[\"mean\"], d[\"std\"]\n",
    "\n",
    "    folder = get_data_location()\n",
    "    ds = datasets.ImageFolder(\n",
    "        folder, transform=transforms.Compose([transforms.ToTensor()])\n",
    "    )\n",
    "    dl = torch.utils.data.DataLoader(\n",
    "        ds, batch_size=1, num_workers=0\n",
    "    )\n",
    "\n",
    "    mean = 0.0\n",
    "    for images, _ in tqdm(dl, total=len(ds), desc=\"Computing mean\", ncols=80):\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "    mean = mean / len(dl.dataset)\n",
    "\n",
    "    var = 0.0\n",
    "    npix = 0\n",
    "    for images, _ in tqdm(dl, total=len(ds), desc=\"Computing std\", ncols=80):\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        var += ((images - mean.unsqueeze(1)) ** 2).sum([0, 2])\n",
    "        npix += images.nelement()\n",
    "\n",
    "    std = torch.sqrt(var / (npix / 3))\n",
    "\n",
    "    # Cache results so we don't need to redo the computation\n",
    "    torch.save({\"mean\": mean, \"std\": std}, cache_file)\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def after_subplot(ax: plt.Axes, group_name: str, x_label: str):\n",
    "    \"\"\"Add title xlabel and legend to single chart\"\"\"\n",
    "    ax.set_title(group_name)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.legend(loc=\"center right\")\n",
    "\n",
    "    if group_name.lower() == \"loss\":\n",
    "        ax.set_ylim([None, 4.5])\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(pred, truth):\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    gt = pd.Series(truth, name='Ground Truth')\n",
    "    predicted = pd.Series(pred, name='Predicted')\n",
    "\n",
    "    confusion_matrix = pd.crosstab(gt, predicted)\n",
    "\n",
    "    fig, sub = plt.subplots(figsize=(14, 12))\n",
    "    with sns.plotting_context(\"notebook\"):\n",
    "        idx = (confusion_matrix == 0)\n",
    "        confusion_matrix[idx] = np.nan\n",
    "        sns.heatmap(confusion_matrix, annot=True, ax=sub, linewidths=0.5, linecolor='lightgray', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T04:10:35.464231Z",
     "iopub.status.busy": "2023-08-28T04:10:35.463784Z",
     "iopub.status.idle": "2023-08-28T04:10:35.488382Z",
     "shell.execute_reply": "2023-08-28T04:10:35.487352Z",
     "shell.execute_reply.started": "2023-08-28T04:10:35.464198Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as T\n",
    "import multiprocessing\n",
    "\n",
    "# from .helpers import compute_mean_and_std, get_data_location\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_data_loaders(\n",
    "    batch_size: int = 32, valid_size: float = 0.2, num_workers: int = 1, limit: int = -1\n",
    "):\n",
    "    \"\"\"\n",
    "    Create and returns the train_one_epoch, validation and test data loaders.\n",
    "\n",
    "    :param batch_size: size of the mini-batches\n",
    "    :param valid_size: fraction of the dataset to use for validation. For example 0.2\n",
    "                       means that 20% of the dataset will be used for validation\n",
    "    :param num_workers: number of workers to use in the data loaders. Use num_workers=1. \n",
    "    :param limit: maximum number of data points to consider\n",
    "    :return a dictionary with 3 keys: 'train_one_epoch', 'valid' and 'test' containing respectively the\n",
    "            train_one_epoch, validation and test data loaders\n",
    "    \"\"\"\n",
    "\n",
    "    # We will fill this up later\n",
    "    data_loaders = {\"train\": None, \"valid\": None, \"test\": None}\n",
    "\n",
    "    base_path = Path(get_data_location())\n",
    "\n",
    "    # Compute mean and std of the dataset\n",
    "    mean, std = compute_mean_and_std()\n",
    "    print(f\"Dataset mean: {mean}, std: {std}\")\n",
    "\n",
    "    # YOUR CODE HERE:\n",
    "    # create 3 sets of data transforms: one for the training dataset,\n",
    "    # containing data augmentation, one for the validation dataset\n",
    "    # (without data augmentation) and one for the test set (again\n",
    "    # without augmentation)\n",
    "    # HINT: resize the image to 256 first, then crop them to 224, then add the\n",
    "    # appropriate transforms for that step\n",
    "#     data_transforms = get_transforms(mean, std, rand_augment_magnitude=9)\n",
    "    data_transforms = {\n",
    "        \"train\": T.Compose(\n",
    "            [\n",
    "                T.Resize(256),\n",
    "                T.RandomCrop(224),\n",
    "                T.RandomHorizontalFlip(0.5),\n",
    "                T.RandAugment(\n",
    "                    num_ops=2,\n",
    "                    magnitude=9,\n",
    "                    interpolation=T.InterpolationMode.BILINEAR,\n",
    "                ),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "        \"valid\": T.Compose(\n",
    "            [\n",
    "                T.Resize(256),\n",
    "                T.RandomCrop(224),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "        \"test\": T.Compose(\n",
    "            [\n",
    "                T.Resize(256),\n",
    "                T.RandomCrop(224),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # Create train and validation datasets\n",
    "    train_data = datasets.ImageFolder(\n",
    "        base_path / \"train\",\n",
    "        # YOUR CODE HERE: add the appropriate transform that you defined in\n",
    "        # the data_transforms dictionary\n",
    "        transform = data_transforms['train']\n",
    "    )\n",
    "    # The validation dataset is a split from the train_one_epoch dataset, so we read\n",
    "    # from the same folder, but we apply the transforms for validation\n",
    "    valid_data = datasets.ImageFolder(\n",
    "        base_path / \"train\",\n",
    "        # YOUR CODE HERE: add the appropriate transform that you defined in\n",
    "        # the data_transforms dictionary\n",
    "        transform = data_transforms['valid']\n",
    "    )\n",
    "\n",
    "    # obtain training indices that will be used for validation\n",
    "    n_tot = len(train_data)\n",
    "    indices = torch.randperm(n_tot)\n",
    "\n",
    "    # If requested, limit the number of data points to consider\n",
    "    if limit > 0:\n",
    "        indices = indices[:limit]\n",
    "        n_tot = limit\n",
    "\n",
    "    split = int(math.ceil(valid_size * n_tot))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation batches\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    valid_sampler  = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # prepare data loaders\n",
    "    data_loaders[\"train\"] = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        sampler=train_sampler,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    data_loaders[\"valid\"] = torch.utils.data.DataLoader(\n",
    "        # YOUR CODE HERE\n",
    "        valid_data,\n",
    "        batch_size=batch_size,\n",
    "        sampler=valid_sampler,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    # Now create the test data loader\n",
    "    test_data = datasets.ImageFolder(\n",
    "        base_path / \"test\",\n",
    "        # YOUR CODE HERE (add the test transform)\n",
    "        transform=data_transforms['test']\n",
    "    )\n",
    "\n",
    "    if limit > 0:\n",
    "        indices = torch.arange(limit)\n",
    "        test_sampler = torch.utils.data.SubsetRandomSampler(indices)\n",
    "    else:\n",
    "        test_sampler = None\n",
    "\n",
    "    data_loaders[\"test\"] = torch.utils.data.DataLoader(\n",
    "        # YOUR CODE HERE (remember to add shuffle=False as well)\n",
    "        test_data,\n",
    "        batch_size=batch_size,\n",
    "        sampler=test_sampler,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return data_loaders\n",
    "\n",
    "\n",
    "def visualize_one_batch(data_loaders, max_n: int = 5):\n",
    "    \"\"\"\n",
    "    Visualize one batch of data.\n",
    "\n",
    "    :param data_loaders: dictionary containing data loaders\n",
    "    :param max_n: maximum number of images to show\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE:\n",
    "    # obtain one batch of training images\n",
    "    # First obtain an iterator from the train dataloader\n",
    "    dataiter  = iter(data_loaders['train'])# YOUR CODE HERE\n",
    "    # Then call the .next() method on the iterator you just\n",
    "    # obtained\n",
    "    images, labels  = dataiter.next()# YOUR CODE HERE\n",
    "\n",
    "    # Undo the normalization (for visualization purposes)\n",
    "    mean, std = compute_mean_and_std()\n",
    "    invTrans = transforms.Compose(\n",
    "        [\n",
    "            transforms.Normalize(mean=[0.0, 0.0, 0.0], std=1 / std),\n",
    "            transforms.Normalize(mean=-mean, std=[1.0, 1.0, 1.0]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    images = invTrans(images)\n",
    "\n",
    "    # YOUR CODE HERE:\n",
    "    # Get class names from the train data loader\n",
    "    class_names  = data_loaders['train'].dataset.classes # YOUR CODE HERE\n",
    "\n",
    "    # Convert from BGR (the format used by pytorch) to\n",
    "    # RGB (the format expected by matplotlib)\n",
    "    images = torch.permute(images, (0, 2, 3, 1)).clip(0, 1)\n",
    "\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(25, 4))\n",
    "    for idx in range(max_n):\n",
    "        ax = fig.add_subplot(1, max_n, idx + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(images[idx])\n",
    "        # print out the correct label for each image\n",
    "        # .item() gets the value contained in a Tensor\n",
    "        ax.set_title(class_names[labels[idx].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T04:10:35.490226Z",
     "iopub.status.busy": "2023-08-28T04:10:35.489848Z",
     "iopub.status.idle": "2023-08-28T04:10:35.501448Z",
     "shell.execute_reply": "2023-08-28T04:10:35.500549Z",
     "shell.execute_reply.started": "2023-08-28T04:10:35.490193Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_loaders = get_data_loaders(batch_size=5,valid_size=0.01)# YOUR CODE HERE\n",
    "\n",
    "# visualize_one_batch(data_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T04:28:23.232003Z",
     "iopub.status.busy": "2023-08-28T04:28:23.231625Z",
     "iopub.status.idle": "2023-08-28T04:28:23.244332Z",
     "shell.execute_reply": "2023-08-28T04:28:23.243158Z",
     "shell.execute_reply.started": "2023-08-28T04:28:23.231970Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# define the CNN architecture\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000, dropout: float = 0.7) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        # Define a CNN architecture. Remember to use the variable num_classes\n",
    "        # to size appropriately the output of your classifier, and if you use\n",
    "        # the Dropout layer, use the variable \"dropout\" to indicate how much\n",
    "        # to use (like nn.Dropout(p=dropout))\n",
    "        \n",
    "        self.backbone = nn.Sequential(\n",
    "                                        nn.Conv2d(3,16,kernel_size=3,padding=1,stride=1),\n",
    "#                                         nn.Dropout2d(0.4), \n",
    "                                        nn.BatchNorm2d(16),\n",
    "                                        nn.LeakyReLU(negative_slope = 0.2),\n",
    "                                        nn.MaxPool2d(2,2), \n",
    "\n",
    "                                        nn.Conv2d(16,32,kernel_size=3,padding=1,stride=1),\n",
    "#                                         nn.Dropout2d(0.4), \n",
    "                                        nn.BatchNorm2d(32),\n",
    "                                        nn.LeakyReLU(negative_slope = 0.2),\n",
    "                                        nn.MaxPool2d(2,2), \n",
    "\n",
    "                                        nn.Conv2d(32,64,kernel_size=3,padding=1,stride=1),\n",
    "#                                         nn.Dropout2d(0.2), \n",
    "                                        nn.BatchNorm2d(64),\n",
    "                                        nn.LeakyReLU(negative_slope = 0.2),\n",
    "                                        nn.MaxPool2d(2,2),\n",
    "            \n",
    "                                        nn.Conv2d(64,128,kernel_size=3,padding=1,stride=1),\n",
    "#                                         nn.Dropout2d(0.2), \n",
    "                                        nn.BatchNorm2d(128),\n",
    "                                        nn.LeakyReLU(negative_slope = 0.2),\n",
    "                                        nn.MaxPool2d(2,2),\n",
    "                                        \n",
    "                                        nn.Flatten()\n",
    "                                    )\n",
    "        \n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "                                    nn.Linear(128*14*14, 512),\n",
    "                                    nn.Dropout(0.4),\n",
    "                                    nn.BatchNorm1d(512),\n",
    "                                    nn.LeakyReLU(negative_slope = 0.2),\n",
    "\n",
    "#                                     nn.Linear(28*28,256),\n",
    "#                                     nn.Dropout(0.2),\n",
    "#                                     nn.BatchNorm1d(256),\n",
    "#                                     nn.ReLU(),\n",
    "                                    \n",
    "                                    nn.Linear(512,num_classes)\n",
    "                                )\n",
    "            \n",
    "                                      \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # YOUR CODE HERE: process the input tensor through the\n",
    "        # feature extractor, the pooling and the final linear\n",
    "        # layers (if appropriate for the architecture chosen)\n",
    "        \n",
    "        x = self.backbone(x)\n",
    "#         x = self.flatten(x)\n",
    "        x = self.head(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T04:10:35.518468Z",
     "iopub.status.busy": "2023-08-28T04:10:35.518128Z",
     "iopub.status.idle": "2023-08-28T04:10:35.530388Z",
     "shell.execute_reply": "2023-08-28T04:10:35.529417Z",
     "shell.execute_reply.started": "2023-08-28T04:10:35.518438Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "\n",
    "\n",
    "def get_loss():\n",
    "    \"\"\"\n",
    "    Get an instance of the CrossEntropyLoss (useful for classification),\n",
    "    optionally moving it to the GPU if use_cuda is set to True\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE: select a loss appropriate for classification\n",
    "    loss  = nn.CrossEntropyLoss() # YOUR CODE HERE\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def get_optimizer(\n",
    "    model: nn.Module,\n",
    "    optimizer: str = \"SGD\",\n",
    "    learning_rate: float = 0.01,\n",
    "    momentum: float = 0.5,\n",
    "    weight_decay: float = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns an optimizer instance\n",
    "\n",
    "    :param model: the model to optimize\n",
    "    :param optimizer: one of 'SGD' or 'Adam'\n",
    "    :param learning_rate: the learning rate\n",
    "    :param momentum: the momentum (if the optimizer uses it)\n",
    "    :param weight_decay: regularization coefficient\n",
    "    \"\"\"\n",
    "    if optimizer.lower() == \"sgd\":\n",
    "        # YOUR CODE HERE: create an instance of the SGD\n",
    "        # optimizer. Use the input parameters learning_rate, momentum\n",
    "        # and weight_decay\n",
    "        opt = torch.optim.SGD(\n",
    "            # YOUR CODE HERE\n",
    "            model.parameters(),\n",
    "            lr = learning_rate,\n",
    "            momentum = momentum,\n",
    "            weight_decay = weight_decay\n",
    "        )\n",
    "\n",
    "    elif optimizer.lower() == \"adam\":\n",
    "        # YOUR CODE HERE: create an instance of the Adam\n",
    "        # optimizer. Use the input parameters learning_rate, momentum\n",
    "        # and weight_decay\n",
    "        opt = torch.optim.Adam(\n",
    "            # YOUR CODE HERE\n",
    "            model.parameters(),\n",
    "            lr = learning_rate,\n",
    "            weight_decay = weight_decay\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Optimizer {optimizer} not supported\")\n",
    "\n",
    "    return opt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T04:10:35.534593Z",
     "iopub.status.busy": "2023-08-28T04:10:35.534082Z",
     "iopub.status.idle": "2023-08-28T04:10:35.569377Z",
     "shell.execute_reply": "2023-08-28T04:10:35.568388Z",
     "shell.execute_reply.started": "2023-08-28T04:10:35.534561Z"
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "from tqdm import tqdm\n",
    "# from src.helpers import after_subplot\n",
    "\n",
    "\n",
    "def train_one_epoch(train_dataloader, model, optimizer, loss):\n",
    "    \"\"\"\n",
    "    Performs one train_one_epoch epoch\n",
    "    \"\"\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # YOUR CODE HERE: transfer the model to the GPU\n",
    "        # HINT: use .cuda()\n",
    "        model.cuda()\n",
    "\n",
    "    # YOUR CODE HERE: set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in tqdm(\n",
    "        enumerate(train_dataloader),\n",
    "        desc=\"Training\",\n",
    "        total=len(train_dataloader),\n",
    "        leave=True,\n",
    "        ncols=80,\n",
    "    ):\n",
    "        # move data to GPU\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        # 1. clear the gradients of all optimized variables\n",
    "        # YOUR CODE HERE:\n",
    "        optimizer.zero_grad()\n",
    "        # 2. forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output  = model(data) # YOUR CODE HERE\n",
    "        # 3. calculate the loss\n",
    "        loss_value  = loss(output,target)# YOUR CODE HERE\n",
    "        # 4. backward pass: compute gradient of the loss with respect to model parameters\n",
    "        # YOUR CODE HERE:\n",
    "        loss_value.backward()\n",
    "        # 5. perform a single optimization step (parameter update)\n",
    "        # YOUR CODE HERE:\n",
    "        optimizer.step()\n",
    "        # update average training loss\n",
    "        train_loss = train_loss + (\n",
    "            (1 / (batch_idx + 1)) * (loss_value.data.item() - train_loss)\n",
    "        )\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def valid_one_epoch(valid_dataloader, model, loss):\n",
    "    \"\"\"\n",
    "    Validate at the end of one epoch\n",
    "    \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # set the model to evaluation mode\n",
    "        # YOUR CODE HERE\n",
    "        model.eval()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            model.cuda()\n",
    "\n",
    "        valid_loss = 0.0\n",
    "        for batch_idx, (data, target) in tqdm(\n",
    "            enumerate(valid_dataloader),\n",
    "            desc=\"Validating\",\n",
    "            total=len(valid_dataloader),\n",
    "            leave=True,\n",
    "            ncols=80,\n",
    "        ):\n",
    "            # move data to GPU\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # 1. forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output  = model(data) # YOUR CODE HERE\n",
    "            # 2. calculate the loss\n",
    "            loss_value  = loss(output,target) # YOUR CODE HERE\n",
    "\n",
    "            # Calculate average validation loss\n",
    "            valid_loss = valid_loss + (\n",
    "                (1 / (batch_idx + 1)) * (loss_value.data.item() - valid_loss)\n",
    "            )\n",
    "\n",
    "    return valid_loss\n",
    "\n",
    "\n",
    "def optimize(data_loaders, model, optimizer, loss, n_epochs, save_path, interactive_tracking=False):\n",
    "    # initialize tracker for minimum validation loss\n",
    "    if interactive_tracking:\n",
    "        liveloss = PlotLosses(outputs=[MatplotlibPlot(after_subplot=after_subplot)])\n",
    "    else:\n",
    "        liveloss = None\n",
    "\n",
    "    valid_loss_min = None\n",
    "    logs = {}\n",
    "\n",
    "    # Learning rate scheduler: setup a learning rate scheduler that\n",
    "    # reduces the learning rate when the validation loss reaches a\n",
    "    # plateau\n",
    "    # HINT: look here: \n",
    "    # https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
    "    scheduler  = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                            mode='min',\n",
    "                                                            factor=0.5,\n",
    "                                                            patience=2,\n",
    "                                                            threshold=1e-2,\n",
    "                                                            verbose=True\n",
    "                                                           ) # YOUR CODE HERE\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        train_loss = train_one_epoch(\n",
    "            data_loaders[\"train\"], model, optimizer, loss\n",
    "        )\n",
    "\n",
    "        valid_loss = valid_one_epoch(data_loaders[\"valid\"], model, loss)\n",
    "\n",
    "        # print training/validation statistics\n",
    "        print(\n",
    "            \"Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}\".format(\n",
    "                epoch, train_loss, valid_loss\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # If the validation loss decreases by more than 1%, save the model\n",
    "        if valid_loss_min is None or (\n",
    "                (valid_loss_min - valid_loss) / valid_loss_min > 0.01\n",
    "        ):\n",
    "            print(f\"New minimum validation loss: {valid_loss:.6f}. Saving model ...\")\n",
    "\n",
    "            # Save the weights to save_path\n",
    "            # YOUR CODE HERE\n",
    "            torch.save(model.state_dict(),save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "        # Update learning rate, i.e., make a step in the learning rate scheduler\n",
    "        # YOUR CODE HERE\n",
    "        scheduler.step(valid_loss)\n",
    "        # Log the losses and the current learning rate\n",
    "        if interactive_tracking:\n",
    "            logs[\"loss\"] = train_loss\n",
    "            logs[\"val_loss\"] = valid_loss\n",
    "            logs[\"lr\"] = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            liveloss.update(logs)\n",
    "            liveloss.send()\n",
    "\n",
    "\n",
    "def one_epoch_test(test_dataloader, model, loss):\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    # set the module to evaluation mode\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # set the model to evaluation mode\n",
    "        # YOUR CODE HERE\n",
    "        model.eval()\n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "\n",
    "        for batch_idx, (data, target) in tqdm(\n",
    "                enumerate(test_dataloader),\n",
    "                desc='Testing',\n",
    "                total=len(test_dataloader),\n",
    "                leave=True,\n",
    "                ncols=80\n",
    "        ):\n",
    "            # move data to GPU\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # 1. forward pass: compute predicted outputs by passing inputs to the model\n",
    "            logits  = model(data)# YOUR CODE HERE\n",
    "            # 2. calculate the loss\n",
    "            loss_value  = loss(logits,target)# YOUR CODE HERE\n",
    "\n",
    "            # update average test loss\n",
    "            test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss_value.data.item() - test_loss))\n",
    "\n",
    "            # convert logits to predicted class\n",
    "            # HINT: the predicted class is the index of the max of the logits\n",
    "            pred  = torch.argmax(logits,dim=1)# YOUR CODE HERE\n",
    "\n",
    "            # compare predictions to true label\n",
    "            correct += torch.sum(torch.squeeze(pred.eq(target.data.view_as(pred))).cpu())\n",
    "            total += data.size(0)\n",
    "\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T04:28:02.224932Z",
     "iopub.status.busy": "2023-08-28T04:28:02.224012Z",
     "iopub.status.idle": "2023-08-28T04:28:02.230969Z",
     "shell.execute_reply": "2023-08-28T04:28:02.229975Z",
     "shell.execute_reply.started": "2023-08-28T04:28:02.224885Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64         # size of the minibatch for stochastic gradient descent (or Adam)\n",
    "valid_size = 0.2        # fraction of the training data to reserve for validation\n",
    "num_epochs = 80         # number of epochs for training\n",
    "num_classes = 50        # number of classes. Do not change this\n",
    "dropout = 0.2           # dropout for our model\n",
    "learning_rate = 0.005   # Learning rate for SGD (or Adam)\n",
    "opt = 'adam'            # optimizer. 'sgd' or 'adam'\n",
    "weight_decay = 0        # regularization. Increase th\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T04:28:27.204553Z",
     "iopub.status.busy": "2023-08-28T04:28:27.204188Z",
     "iopub.status.idle": "2023-08-28T05:46:04.230182Z",
     "shell.execute_reply": "2023-08-28T05:46:04.229048Z",
     "shell.execute_reply.started": "2023-08-28T04:28:27.204524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from src.data import get_data_loaders\n",
    "# from src.train import optimize\n",
    "# from src.optimization import get_optimizer, get_loss\n",
    "# from src.model import MyModel\n",
    "\n",
    "# get the data loaders using batch_size and valid_size defined in the previous\n",
    "# cell\n",
    "# HINT: do NOT copy/paste the values. Use the variables instead\n",
    "data_loaders = get_data_loaders(batch_size=batch_size, valid_size=valid_size)# YOUR CODE HERE\n",
    "\n",
    "# instance model MyModel with num_classes and drouput defined in the previous\n",
    "# cell\n",
    "model = MyModel(num_classes,dropout) # YOUR CODE HERE\n",
    "\n",
    "# Get the optimizer using get_optimizer and the model you just created, the learning rate,\n",
    "# the optimizer and the weight decay specified in the previous cell\n",
    "optimizer = get_optimizer(model=model, optimizer=opt, learning_rate=learning_rate, weight_decay=weight_decay) # YOUR CODE HERE\n",
    "\n",
    "# Get the loss using get_loss\n",
    "loss = get_loss() # YOUR CODE HERE\n",
    "\n",
    "optimize(\n",
    "    data_loaders,\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    n_epochs=num_epochs,\n",
    "    save_path=\"best_val_loss.pt\",\n",
    "    interactive_tracking=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T05:46:04.233418Z",
     "iopub.status.busy": "2023-08-28T05:46:04.232731Z",
     "iopub.status.idle": "2023-08-28T05:46:15.072218Z",
     "shell.execute_reply": "2023-08-28T05:46:15.071010Z",
     "shell.execute_reply.started": "2023-08-28T05:46:04.233376Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████████████████████████████| 20/20 [00:10<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.835772\n",
      "\n",
      "\n",
      "Test Accuracy: 53% (665/1250)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8357716858386992"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "import torch\n",
    "\n",
    "model = MyModel(num_classes=num_classes, dropout=dropout)\n",
    "\n",
    "# YOUR CODE HERE: load the weights in 'checkpoints/best_val_loss.pt'\n",
    "model.load_state_dict(torch.load('best_val_loss.pt'))\n",
    "# Run test\n",
    "one_epoch_test(data_loaders['test'], model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-27T13:42:54.418250Z",
     "iopub.status.idle": "2023-08-27T13:42:54.418621Z",
     "shell.execute_reply": "2023-08-27T13:42:54.418463Z",
     "shell.execute_reply.started": "2023-08-27T13:42:54.418446Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "# from .helpers import get_data_location\n",
    "\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "\n",
    "    def __init__(self, model, class_names, mean, std):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model.eval()\n",
    "        self.class_names = class_names\n",
    "\n",
    "        # We use nn.Sequential and not nn.Compose because the former\n",
    "        # is compatible with torch.script, while the latter isn't\n",
    "        self.transforms = nn.Sequential(\n",
    "            T.Resize([256, ]),  # We use single int value inside a list due to torchscript type restrictions\n",
    "            T.CenterCrop(224),\n",
    "            T.ConvertImageDtype(torch.float),\n",
    "            T.Normalize(mean.tolist(), std.tolist())\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            # 1. apply transforms\n",
    "            x  = self.transfroms(x) # YOUR CODE HERE\n",
    "            # 2. get the logits\n",
    "            x  = self.model(x) # YOUR CODE HERE\n",
    "            # 3. apply softmax\n",
    "            #    HINT: remmeber to apply softmax across dim=1\n",
    "            softmax_layer = nn.Softmax(dim=1)\n",
    "            x  = softmax_layer(x) # YOUR CODE HERE\n",
    "\n",
    "            return x\n",
    "\n",
    "\n",
    "def predictor_test(test_dataloader, model_reloaded):\n",
    "    \"\"\"\n",
    "    Test the predictor. Since the predictor does not operate on the same tensors\n",
    "    as the non-wrapped model, we need a specific test function (can't use one_epoch_test)\n",
    "    \"\"\"\n",
    "\n",
    "    folder = get_data_location()\n",
    "    test_data = datasets.ImageFolder(os.path.join(folder, \"test\"), transform=T.ToTensor())\n",
    "\n",
    "    pred = []\n",
    "    truth = []\n",
    "    for x in tqdm(test_data, total=len(test_dataloader.dataset), leave=True, ncols=80):\n",
    "        softmax = model_reloaded(x[0].unsqueeze(dim=0))\n",
    "\n",
    "        idx = softmax.squeeze().argmax()\n",
    "\n",
    "        pred.append(int(x[1]))\n",
    "        truth.append(int(idx))\n",
    "\n",
    "    pred = np.array(pred)\n",
    "    truth = np.array(truth)\n",
    "\n",
    "    print(f\"Accuracy: {(pred==truth).sum() / pred.shape[0]}\")\n",
    "\n",
    "    return truth, pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-27T13:42:54.421257Z",
     "iopub.status.idle": "2023-08-27T13:42:54.422087Z",
     "shell.execute_reply": "2023-08-27T13:42:54.421861Z",
     "shell.execute_reply.started": "2023-08-27T13:42:54.421837Z"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: you might need to restart the notebook before running this step\n",
    "# If you get an error about RuntimeError: Can't redefine method: forward on class\n",
    "# restart your notebook then execute only this cell\n",
    "# from src.predictor import Predictor\n",
    "# from src.helpers import compute_mean_and_std\n",
    "# from src.model import MyModel\n",
    "# from src.data import get_data_loaders\n",
    "import torch\n",
    "\n",
    "data_loaders = get_data_loaders(batch_size=1)\n",
    "\n",
    "# First let's get the class names from our data loaders\n",
    "class_names = data_loaders[\"train\"].dataset.classes\n",
    "\n",
    "# Then let's move the model_transfer to the CPU\n",
    "# (we don't need GPU for inference)\n",
    "model = MyModel(num_classes=50, dropout=0.5).cpu()\n",
    "\n",
    "# Let's make sure we use the right weights by loading the\n",
    "# best weights we have found during training\n",
    "# NOTE: remember to use map_location='cpu' so the weights\n",
    "# are loaded on the CPU (and not the GPU)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model.load(torch.load('best_val_loss.pt',map_location='cpu'))\n",
    "# Let's wrap our model using the predictor class\n",
    "mean, std = compute_mean_and_std()\n",
    "predictor = Predictor(model, class_names, mean, std).cpu()\n",
    "\n",
    "# Export using torch.jit.script\n",
    "scripted_predictor = torch.jit.script(predictor) # YOUR CODE HERE\n",
    "\n",
    "scripted_predictor.save(\"original_exported.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
